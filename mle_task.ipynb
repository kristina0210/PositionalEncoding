{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q7iS3C-dFmm"
      },
      "source": [
        "## Qing Xiong -- MLE Intern Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWxfNVXDdFmp"
      },
      "source": [
        "### Question 1: Suppose that we design a deep architecture to represent a sequence by stacking self-attention layers with positional encoding. What could be issues? (paragraph format)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY6jzMFtdFmq"
      },
      "source": [
        "#### Answer:\n",
        "\n",
        "A deep network that represents a squence by stacking self-attention layers with positional encoding could have multiple issues. First of all, the attention layers can be computationally costly as the sequence length and number of layers increase, and it also requires a lot of memory for computing attention. Such deep architecture might cause overfitting when training dataset is small. Besides, when the model gets deeper and deeper, a fixed positional encoding might be insufficient for certain tasks and the model itself also gets harder to interpret."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyg2sx8HdFmq"
      },
      "source": [
        "### Question2: Can you design a learnable positional encoding method? (Create dummy dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4WCW1YrsdFmq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import random\n",
        "from torch.nn.utils.rnn import pad_sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Px2d0IzXdFms"
      },
      "outputs": [],
      "source": [
        "## dataset class\n",
        "class DummyDataset(Dataset):\n",
        "    def __init__(self, max_seq_len, num_samples):\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.num_samples = num_samples\n",
        "        # create dummy data with randomized vector & length\n",
        "        self.data = [torch.randint(0, 100, (random.randint(1, max_seq_len),)) for _ in range(num_samples)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence = self.data[idx]\n",
        "        positions = torch.arange(len(sequence))\n",
        "        return sequence, positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "splz3DOpdFms"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters for the dataset\n",
        "batch_size = 32\n",
        "num_samples = 1000\n",
        "max_seq_len = 20\n",
        "\n",
        "def collate_fn(batch):\n",
        "    sequences, positions = zip(*batch)\n",
        "    sequences_pad = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
        "    positions_pad = pad_sequence(positions, batch_first=True, padding_value=-1)\n",
        "    return sequences_pad, positions_pad\n",
        "\n",
        "# Create the dataset and dataloader\n",
        "dataset = DummyDataset(max_seq_len, num_samples)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6ge-DaT9dFmt"
      },
      "outputs": [],
      "source": [
        "# reference: https://arxiv.org/pdf/1705.03122.pdf 3.1 positional embeddings\n",
        "# e = (w1 + p1, . . . , wm + pm)\n",
        "class LearnablePositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(LearnablePositionalEncoding, self).__init__()\n",
        "\n",
        "        # Embedding layers for token and positional information\n",
        "        self.token_embedding = nn.Embedding(100, d_model)  # Assuming tokens are integers from 0 to 99\n",
        "        self.pos_embedding = nn.Embedding(max_len, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_len]\n",
        "\n",
        "        # Get token embeddings\n",
        "        x = self.token_embedding(x)\n",
        "\n",
        "        # Generate position indices\n",
        "        pos_indices = torch.arange(x.size(1)).unsqueeze(0).expand(x.size(0), -1).to(x.device)\n",
        "\n",
        "        # Return the sum of token and positional embeddings\n",
        "        return x + self.pos_embedding(pos_indices)\n",
        "\n",
        "class PositionPredictor(nn.Module):\n",
        "    def __init__(self, d_model, max_len):\n",
        "        super().__init__()\n",
        "        self.pos_enc = LearnablePositionalEncoding(d_model, max_len)\n",
        "        self.linear = nn.Linear(d_model, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pos_enc(x)\n",
        "\n",
        "        return self.linear(x).squeeze(-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YODGoQQdFmt",
        "outputId": "ef789e97-888d-479a-c7c3-a4093667caf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 58.27162551879883\n",
            "Epoch 2, Loss: 55.42763137817383\n",
            "Epoch 3, Loss: 52.194889068603516\n",
            "Epoch 4, Loss: 48.48335647583008\n",
            "Epoch 5, Loss: 44.3350944519043\n",
            "Epoch 6, Loss: 39.89034652709961\n",
            "Epoch 7, Loss: 35.34430694580078\n",
            "Epoch 8, Loss: 30.909711837768555\n",
            "Epoch 9, Loss: 26.77927589416504\n",
            "Epoch 10, Loss: 23.08452606201172\n",
            "Epoch 11, Loss: 19.875179290771484\n",
            "Epoch 12, Loss: 17.128015518188477\n",
            "Epoch 13, Loss: 14.781341552734375\n",
            "Epoch 14, Loss: 12.767078399658203\n",
            "Epoch 15, Loss: 11.02596378326416\n",
            "Epoch 16, Loss: 9.511139869689941\n",
            "Epoch 17, Loss: 8.186941146850586\n",
            "Epoch 18, Loss: 7.026272296905518\n",
            "Epoch 19, Loss: 6.008105754852295\n",
            "Epoch 20, Loss: 5.115661144256592\n",
            "Epoch 21, Loss: 4.335185527801514\n",
            "Epoch 22, Loss: 3.6551496982574463\n",
            "Epoch 23, Loss: 3.065659523010254\n",
            "Epoch 24, Loss: 2.557969093322754\n",
            "Epoch 25, Loss: 2.1240713596343994\n"
          ]
        }
      ],
      "source": [
        "# Instantiate model and optimizer\n",
        "model = PositionPredictor(d_model=16, max_len=20)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Start training (for 25 epochs)\n",
        "for epoch in range(25): \n",
        "    for sequences, positions in dataloader:\n",
        "\n",
        "        # print(sequences.size())\n",
        "        outputs = model(sequences)\n",
        "\n",
        "        # Mask to ignore padded positions\n",
        "        mask = positions != -1\n",
        "        outputs = outputs[mask]\n",
        "        positions = positions[mask]\n",
        "\n",
        "        loss = criterion(outputs, positions.float())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvg4p_pidFmu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
